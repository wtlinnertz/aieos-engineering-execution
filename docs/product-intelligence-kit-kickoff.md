# Product Intelligence Kit — Kickoff Document

Paste this entire document into the Claude session for your new `aieos-product-intelligence-kit` project. It contains everything the AI needs to bootstrap the kit correctly.

---

## Kickoff Prompt

You are bootstrapping the **aieos-product-intelligence-kit** — a new kit in the AIEOS system. This kit governs the space between strategic intent and engineering-ready product requirements.

### Your Mission

Build a structured documentation kit following the AIEOS governance model (included below). This kit covers the **Product Intelligence** layer — the artifacts and processes that transform business strategy into validated, engineering-ready product requirements.

### Proposed Artifacts

The following artifact types are candidates for this kit. **Your first task is to validate this list** — determine whether these are the right artifacts, whether any should be combined or split, and whether the flow is correct. Do not assume this list is final.

Candidates:
1. **Problem Framing Document** — Structures the problem space, user pain points, and opportunity sizing
2. **Value Hypothesis** — Testable bets about what will drive user/business value
3. **Assumption Register** — Explicit assumptions with validation plans and risk levels
4. **Discovery PRD** — The engineering-ready product requirements document (this kit's terminal output)

The Discovery PRD is the **handoff artifact** to the Engineering Execution Kit. It must satisfy the PRD spec defined by that kit (included below as the downstream contract).

### Downstream Handoff Contract

The Engineering Execution Kit accepts a frozen PRD as its entry point. The PRD must satisfy these hard gates and content rules (this is the full PRD specification from the downstream kit):

---

#### PRD Specification (from Engineering Execution Kit)

The PRD defines the problem, goals, scope, and success criteria for a product initiative. It must be clear enough to drive architecture without containing solutions.

**Upstream Dependencies**
- Product Brief (intake form) or equivalent problem description

**Required Sections**
1. Document Control
2. Problem Statement
3. Goals (What "Success" Means)
4. Non-Goals (Hard Exclusions)
5. Users / Personas
6. Requirements (Functional and Non-Functional)
7. Constraints (Hard Guardrails)
8. Assumptions
9. Out of Scope by Default
10. Open Questions
11. Acceptance / Success Criteria
12. Freeze Declaration

**Content Rules**

Problem Statement:
- Must contain a clear problem statement
- Must identify who experiences the problem (users or personas)
- Must include rationale ("why now")

Goals & Success Criteria:
- Goals must be explicit and stated as measurable outcomes
- Success criteria must be measurable or objectively verifiable

Scope & Non-Goals:
- In-scope functionality must be clearly defined
- Non-goals must be explicitly listed as hard exclusions
- No implied scope — anything not listed in §2 and §5 is out of scope by default

Requirements:
- Functional requirements must be explicitly stated
- Non-functional requirements must be explicitly stated (performance, reliability, compliance, etc.)
- Requirements must not contain implementation details or solution design

Constraints & Assumptions:
- Constraints must be documented (regulatory, technical, delivery)
- Assumptions must be documented with note that if false, they change scope or direction

Readiness:
- No unresolved critical questions that would block architecture
- PRD must be internally consistent (goals, scope, requirements, and non-goals do not contradict)

**Format Requirements**
- Functional requirements should use "The system SHALL ..." language
- Each requirement should have a unique identifier (FR-1, NFR-1, etc.)

**Completeness Rules**
- All required sections must be present
- Problem statement must answer what, who, and why
- At least one functional requirement and one non-functional requirement must exist
- Non-goals must be present (empty non-goals section is a failure unless justified)
- Open questions section must exist (may be empty if all questions are resolved)

**Relationship Rules**
- PRD must not contain solution design or architecture
- PRD must not reference implementation details
- PRD defines intent that downstream artifacts (SAD, TDD) must not reinterpret or expand
- Non-goals are enforceable constraints on all downstream artifacts

**Hard Gates**
1. **problem_definition** — Clear problem statement with identified users and rationale
2. **goals** — Explicit goals with measurable success criteria
3. **scope** — In-scope clearly defined, explicit non-goals, no implied scope
4. **requirements** — Functional and non-functional requirements explicitly stated
5. **constraints** — Constraints and assumptions documented
6. **readiness** — No unresolved critical questions, internally consistent

---

#### Product Brief Template (from Engineering Execution Kit)

This is the intake form the Engineering Execution Kit uses to feed PRD generation. Your Discovery PRD should produce output that is at least as complete as what this intake form captures — this is the minimum bar for what the downstream kit expects.

# Product Brief (PRD Intake)

A lightweight intake form for capturing product intent before generating a PRD.
This is a **human-authored input**, not an AI-generated artifact.

Fill in what you know. Leave unknown sections blank — the PRD generation prompt will mark them as "Not provided."

**Why**

Objective:
- What is the feature or enhancement trying to achieve?
- What business objective does it address?
- What outcomes are expected?

Current Problem:
- What issue does this solve?
- What pain points or inefficiencies exist today?
- Who is impacted and how?
- What data quantifies this problem?

**What**

Functional Requirements:
- What should the system do?
- What are the key use cases?
- What are the acceptance criteria?

Scope:
- What is in scope for this effort?
- What is explicitly out of scope?
- Are there technical, budgetary, or timeline constraints?

Exclusions:
- What related functionality is intentionally excluded?
- Why is it excluded?

Reference Documents:
- Links to relevant background material

**Who**

Target Personas:
- Who are the primary users or beneficiaries?
- Are there users with conflicting needs?

External Dependencies:
- What other teams, vendors, or systems are involved?
- What integrations or handoffs are required?

Sponsor:
- Who is the business sponsor or decision-maker?

Blockers:
- What risks or issues could prevent progress?
- Are there unresolved decisions or resource gaps?

**When**

Release Criteria:
- What must be true before this goes live?
- Are there quality, security, or documentation gates?

Success Criteria:
- What does success look like post-launch?
- What metrics or KPIs will be tracked?

Timeline:
- What is the expected timeline?
- Are there dependencies or sequencing concerns?

**How (Non-Functional)**

Non-Functional Requirements:
- What are the performance, scalability, and reliability targets?
- Are there SLAs or SLOs?

Assumptions:
- What conditions are assumed to be true?
- What happens if they change?

Risks:
- What could go wrong?
- What are the mitigation strategies?

Compliance:
- What security controls must be in place?
- Are there regulatory or policy requirements?

**Completeness Checklist**

Before handing this to the PRD generation prompt, confirm:
- [ ] Problem is clearly stated
- [ ] At least one goal or outcome is defined
- [ ] Scope boundaries are explicit (in scope and out of scope)
- [ ] Primary users or personas are identified
- [ ] Known constraints are listed

---

### Governance Model

This is the authoritative structural reference for all AIEOS kits. Your kit must follow these rules exactly.

---

# AIEOS Governance Model

This document defines the structural rules, taxonomy, and invariants that govern every kit in the AIEOS system. It is the single source of truth for how kits are built, how artifacts behave, and how kits connect.

Any kit that follows this model is structurally compatible with every other kit in the system.

---

## 1. The Kit Model

A **kit** is a self-contained repository that governs one layer of the organization's operating system. Each kit provides the rules, templates, prompts, and validators needed to produce and verify artifacts within its domain.

Every kit is:
- **Standalone** — its own repository, versioned independently
- **Self-documenting** — all rules are in the repo, not in tribal knowledge
- **AI-native** — designed to be operated by AI assistants under human oversight
- **Tool-agnostic** — no references to specific vendors in policy files (tool mappings go in bindings)

---

## 2. The Four-File System

Every artifact type within a kit is governed by exactly four files. Each file answers one question.

| File | Question | Responsibility |
|------|----------|---------------|
| **Spec** | What are the rules? | Content rules, format requirements, hard gates, quality criteria |
| **Template** | What is the structure? | Section headings, ordering, placeholders — structure only |
| **Prompt** | How should the AI behave? | Generation instructions, input requirements, behavioral constraints |
| **Validator** | How do we judge pass/fail? | Evaluation procedure, hard gate checks, output format |

### Separation of Concerns

- **Specs are the single source of truth.** Hard gates, content rules, and quality criteria are defined in specs. Prompts and validators reference specs — they never inline their own rules.
- **Templates define structure, not content.** A template contains section headings and placeholders. It does not contain content rules or quality criteria.
- **Prompts define behavior, not rules.** A prompt tells the AI what to do and what inputs to use. It references the spec for the actual rules.
- **Validators judge, they do not help.** A validator evaluates what is present against the spec. It does not suggest improvements, redesign artifacts, or expand scope.

### When Files Reference Each Other

```
Prompt → references → Spec (for content rules to satisfy)
Prompt → references → Template (for structure to follow)
Validator → references → Spec (for hard gates to evaluate against)
```

No other cross-references are permitted. Templates do not reference specs. Validators do not reference prompts.

---

## 3. Repository Structure

Every kit follows this directory layout:

```
aieos-{layer-name}-kit/
  docs/
    principles/      # Organizational policy (input material, not governed artifacts)
    specs/           # Content rules and quality criteria per artifact type
    artifacts/       # Templates and intake forms
    prompts/         # AI generation prompts
    validators/      # Quality gate definitions
    playbook.md      # End-to-end process definition for this kit
    index.md         # Documentation entry point
    how-to-adapt.md  # Organizational adoption guidance
    how-to-use-with-ai.md  # AI tool usage guide
  examples/          # Worked examples demonstrating the full flow
  tests/             # Test plans and structural verification
  CLAUDE.md          # AI tool project instructions (Claude Code)
  README.md          # Repository overview
```

### Directory Responsibilities

| Directory | Contains | Does Not Contain |
|-----------|----------|-----------------|
| `principles/` | Organizational policy documents that feed artifact generation | Artifact specs, hard gates, or validation criteria |
| `specs/` | Authoritative content rules and hard gates per artifact type | Templates, prompts, or generation logic |
| `artifacts/` | Structural templates and human intake forms | Content rules or quality criteria |
| `prompts/` | AI behavior instructions for generation and utility tasks | Inline rules (must reference specs) |
| `validators/` | Evaluation procedures and judgment criteria | Suggestions, redesign, or scope expansion |

---

## 4. Naming Conventions

### File Naming

| File Type | Pattern | Example |
|-----------|---------|---------|
| Spec | `{type}-spec.md` | `prd-spec.md` |
| Template | `{type}-template.md` | `prd-template.md` |
| Intake form | `{context}-template.md` | `architecture-context-template.md` |
| Generation prompt | `{type}-prompt.md` | `prd-prompt.md` |
| Utility prompt | `{function}-prompt.md` | `codebase-analysis-prompt.md` |
| Validator | `{type}-validator.md` | `prd-validator.md` |
| Example artifact | `{nn}-{type}.md` | `01-prd.md` |

### Kit Naming

Kit repositories follow the pattern: `aieos-{layer-name}-kit`

| Layer | Repository Name |
|-------|----------------|
| Strategic Direction | `aieos-strategic-direction-kit` |
| Product Intelligence | `aieos-product-intelligence-kit` |
| Flow Control | `aieos-flow-control-kit` |
| Engineering Execution | `aieos-engineering-execution-kit` |
| Release & Exposure | `aieos-release-exposure-kit` |
| Reliability & Resilience | `aieos-reliability-resilience-kit` |
| Insight & Evolution | `aieos-insight-evolution-kit` |

### Artifact ID Format

`{TYPE}-{PROJECT}-{NNN}`

- `TYPE`: Uppercase abbreviation of the artifact type (e.g., `PRD`, `SAD`, `OKR`, `SLO`)
- `PROJECT`: Short project identifier
- `NNN`: Sequential number, zero-padded to 3 digits

Example: `PRD-PAYMENTS-001`, `SLO-API-003`

### Project Artifact Directory

Generated artifacts live in the consuming project's repository under `docs/sdlc/`:

```
my-app/
  docs/sdlc/
    00-product-brief.md          ← human input (intake form)
    01-prd.md                    ← generated, validated, frozen
    01-prd-validation.json       ← final passing validator result
    02-acf.md
    ...
```

The `00-` prefix groups human inputs before generated artifacts. Numbered prefixes follow artifact flow order.

---

## 5. Validator Output Format

All validators across all kits produce JSON with this schema:

```json
{
  "status": "PASS | FAIL",
  "summary": "<one sentence verdict>",
  "hard_gates": { "<gate_name>": "PASS | FAIL" },
  "blocking_issues": [{ "gate": "", "description": "", "location": "" }],
  "warnings": [{ "description": "", "location": "" }],
  "completeness_score": "<0-100>"
}
```

### Interpretation Rules

- Any hard gate failure means `FAIL` — no exceptions.
- `blocking_issues` identifies exactly what failed and where.
- `warnings` are non-blocking observations. They do not affect the status.
- `completeness_score` is advisory. It does not override hard gate results.
- Validators evaluate only what is explicitly present. They do not infer, assume, or speculate.
- Ambiguity in the artifact is a failure condition, not a judgment call.

---

## 6. Artifact Promotion Model

### Promotion Rules

1. Artifacts are **generated**, **validated**, and **frozen** — in that order.
2. A frozen artifact is immutable. Changes require the re-entry protocol.
3. Downstream artifacts may not expand scope beyond what upstream artifacts define.
4. Prerequisite artifacts must be frozen before downstream generation begins.
5. Generation and validation happen in **separate AI sessions** to prevent self-validation bias.

### Freeze Semantics

A freeze means:
- The artifact has passed its validator (all hard gates PASS).
- A human has reviewed and approved it.
- It is now the authoritative input for downstream artifacts.
- It may not be modified without triggering impact analysis and re-validation of all downstream artifacts.

### Re-Entry Protocol

When a frozen artifact must change:
1. Run impact analysis to assess downstream effects.
2. Modify the artifact.
3. Re-validate the modified artifact.
4. Re-validate all affected downstream artifacts.
5. Obtain human approval at each step.

---

## 7. The Playbook

Every kit has a `playbook.md` that defines:
- The artifact flow (the non-negotiable order of generation and validation)
- The inputs and outputs of each step
- The freeze points
- The re-entry protocol for that kit's artifacts
- Any kit-specific iteration or escalation rules

The playbook is the process definition. It is not a tutorial — that's what `how-to-use-with-ai.md` is for.

---

## 8. Principles and Standards

### What Principles Are

Principles are **organizational policy documents** that define how the organization operates within the kit's domain. They are input material for artifact generation — not governed artifacts themselves.

Principles answer: **"What standards does this organization hold?"**

### What Principles Are Not

Principles do not define:
- What makes an artifact document good (that's what specs do)
- How AI should behave when generating (that's what prompts do)
- How to judge pass/fail (that's what validators do)

### Principles Structure

Each kit's `principles/` directory contains domain-relevant policy files. Examples:

| Kit | Principle Files |
|-----|----------------|
| Engineering Execution | `code-craftsmanship.md`, `product-craftsmanship.md` |
| Release & Exposure | `deployment-policy.md`, `progressive-delivery-policy.md` |
| Reliability & Resilience | `slo-policy.md`, `incident-management-policy.md` |

Principles feed into the kit's context files (ACF, DCF, or kit-specific equivalents), which translate policy into enforceable guardrails.

---

## 9. Intake Forms

### Purpose

Intake forms bridge human intent and AI generation. They structure human thinking into machine-consumable input so the AI has concrete material to work with — not vague intent.

### Design Rules

- Intake forms are **templates with structured questions**, not blank pages.
- They may be filled by humans directly or pre-filled by analysis prompts (e.g., codebase analysis for brownfield projects).
- Pre-filled forms must be reviewed and edited by a human before use as generation input.
- Intake forms live in `docs/artifacts/` alongside the artifact templates they feed.

### Brownfield Support

For kits operating on existing systems (not greenfield), provide:
1. An **analysis prompt** that examines the current state and produces structured output.
2. The analysis output maps to the intake form's sections.
3. The human reviews, corrects, and approves before using as input.

This pattern prevents the AI from generating artifacts based on assumptions about existing systems.

---

## 10. Inter-Kit Interfaces

### Handoff Contracts

When one kit's output becomes another kit's input, the relationship is defined as a **handoff contract**. Each kit's playbook documents:

- **Upstream**: What this kit accepts as input and from which kit.
- **Downstream**: What this kit produces as output and which kit consumes it.

### Contract Format

A handoff contract specifies:
- The artifact type being handed off
- The required state (must be frozen and validated)
- The specific sections or fields the downstream kit depends on
- What happens if the upstream artifact changes (re-entry trigger)

### Example: Engineering Execution ↔ Product Intelligence

```
Product Intelligence Kit
  Output: Frozen Discovery PRD (validated, approved)

Engineering Execution Kit
  Input: Frozen PRD (from Product Intelligence Kit or direct human input)
  Dependency: PRD §1 Problem Statement, §2 Goals, §3 Non-Goals, §10 Acceptance Criteria
  Re-entry trigger: Any change to PRD goals, scope, or acceptance criteria
```

### Cross-Kit Consistency

When artifacts from different kits reference each other, consistency must be verified at handoff boundaries. Each kit is responsible for validating that its inputs meet its intake requirements — it does not trust upstream kits blindly.

---

## 11. AI Operating Rules

### Generation Rules

When generating artifacts:
- Output pure Markdown.
- Use the template exactly as written — do not add or remove sections.
- Satisfy all content rules, format requirements, and hard gates defined in the corresponding spec.
- Do not infer missing information — mark it explicitly.
- Do not expand scope beyond upstream artifacts.
- Non-goals are enforceable — do not violate them.

### Validation Rules

When validating artifacts:
- Evaluate against the hard gates and content rules defined in the corresponding spec.
- Be strict — ambiguity is a failure condition.
- Do not redesign or suggest solutions.
- Evaluate only what is explicitly present.
- Any hard gate failure means FAIL.

### Session Discipline

- One artifact per session for generation.
- Separate sessions for generation and validation.
- Include the full frozen upstream artifacts — do not summarize.
- Include the spec, prompt, and template for generation sessions.
- Include the spec and validator for validation sessions.

---

## 12. Tool Bindings

### Policy vs Implementation

Kits define **policy** — the rules, constraints, and quality criteria. When a kit must reference specific tools (Jira, ServiceNow, LaunchDarkly, etc.), the tool-specific details go in a **bindings file**, not in the policy files.

### Bindings Structure

```
docs/
  bindings/
    jira-mapping.md           # Maps kit concepts to Jira fields/workflows
    servicenow-mapping.md     # Maps kit concepts to ServiceNow
    launchdarkly-mapping.md   # Maps feature flag policy to LaunchDarkly
```

When the organization changes tools, only bindings files are updated. Specs, templates, prompts, and validators remain unchanged.

Bindings are not governed artifacts — they have no spec, validator, or prompt. They are reference material maintained by the team responsible for the tooling.

---

## 13. Kit Invariants

The following rules apply to every kit in the AIEOS system. Violating these breaks the system's guarantees.

### Structural Invariants

1. **Four-file completeness** — Every artifact type has exactly four files: spec, template, prompt, validator.
2. **Specs are the single source of truth** — Prompts and validators reference specs. Rules are never inlined.
3. **Validators are hard gates** — Ambiguity is failure. Validators do not help, suggest, or redesign.
4. **Non-goals are enforceable** — Validators block violations. Scope expansion is not permitted.

### Process Invariants

5. **Freeze before promote** — Upstream artifacts must be frozen before downstream generation.
6. **Separate generation and validation** — Different AI sessions to prevent self-validation bias.
7. **Human in the loop** — Every freeze requires human approval. AI does not self-approve.
8. **Impact before re-entry** — Changes to frozen artifacts require impact analysis first.

### Quality Invariants

9. **No silent modification** — Do not change existing constraints without explicit acknowledgment.
10. **No scope expansion** — Downstream artifacts may not introduce scope that upstream artifacts do not define.
11. **No inferred information** — If information is missing, mark it explicitly. Do not fill gaps with assumptions.

---

## 14. Adopting This Model

### For a New Kit

1. Create the repository following the naming convention (`aieos-{layer-name}-kit`).
2. Set up the directory structure from §3.
3. Write the playbook first — define the artifact flow, freeze points, and inputs/outputs.
4. For each artifact type, write files in this order: validator → spec → template → prompt. Starting with the validator forces you to define "what does good look like?" before generating anything.
5. Create intake forms for any artifact that requires human input.
6. Write a worked example that exercises the full flow.
7. Run structural integrity checks (four-file completeness, cross-reference verification, naming compliance).

### For an Existing Kit

1. Audit against the structural invariants (§13).
2. Identify any specs with inline rules in prompts or validators — extract to specs.
3. Verify naming conventions match §4.
4. Ensure the playbook documents the full flow including freeze points and re-entry.
5. Add inter-kit interface documentation if the kit has upstream or downstream dependencies.

### Starting Order

Do not build all kits simultaneously. Start with 2–3 kits that have direct handoff relationships to prove the inter-kit contract model:

1. **Engineering Execution Kit** (proven — this is the reference implementation)
2. **Product Intelligence Kit** (direct upstream — its outputs become Engineering Execution inputs)
3. **Release & Exposure Kit** (direct downstream — consumes Engineering Execution outputs)

Extract shared governance to a dedicated repo only when duplication across 3+ kits becomes painful.

---

## 15. Versioning and Evolution

### Kit Versioning

Each kit is versioned independently using semantic versioning:
- **Major**: Breaking changes to artifact structure, hard gates, or inter-kit contracts.
- **Minor**: New artifact types, additional hard gates, new intake forms.
- **Patch**: Clarifications, typo fixes, example updates.

### Governance Model Versioning

This document is versioned alongside the kit that hosts it. When it moves to a shared location, it gets its own version.

### Change Protocol

Changes to the governance model require:
1. Impact analysis across all kits that reference it.
2. Review by kit maintainers.
3. Migration guidance for breaking changes.

---

## Summary

The AIEOS governance model ensures every kit is structurally consistent, independently operable, and safely connectable. The rules are intentionally rigid where they matter (file taxonomy, validation semantics, promotion model) and intentionally flexible where they should be (domain-specific artifacts, organizational principles, tool bindings).

Adapt the **edges**, not the **core**.

---

### Artifact Flow (Define This)

Determine the artifact flow for this kit. It should follow this pattern:
1. Intake form(s) → first artifact → validate → freeze
2. Frozen artifact → next artifact → validate → freeze
3. ... continue until the terminal artifact (Discovery PRD)
4. Discovery PRD → validate → freeze → hand off to Engineering Execution Kit

### Build Order

Follow the governance model §14 build order:
1. **Playbook first** — define the artifact flow, freeze points, inputs/outputs
2. **For each artifact type**: spec → template → prompt → validator (the governance model says validator first, but if you're defining the domain for the first time, spec first makes more sense — use your judgment)
3. **Intake forms** for any artifact requiring human input
4. **Worked example** exercising the full flow
5. **Structural checks** (four-file completeness, naming compliance)

### Key Constraints

- This kit's terminal output (Discovery PRD) must satisfy the Engineering Execution Kit's PRD spec exactly
- Follow all 13 kit invariants from the governance model
- Tool-agnostic — no vendor references in policy files
- AI-native — designed for AI assistants under human oversight
- The kit must be useful for both greenfield initiatives and product evolution of existing systems

### Principles Files

This kit should have its own `principles/` directory with product-domain policy files. Consider what organizational standards belong here (e.g., `product-discovery-principles.md`, `hypothesis-testing-standards.md`). These are input material, not governed artifacts.

### What NOT to Do

- Do not copy the Engineering Execution Kit's artifacts — this is a different domain
- Do not make validators helpful — they judge, they do not suggest
- Do not inline rules in prompts or validators — specs are the source of truth
- Do not add tool-specific references to policy files
- Do not skip the four-file system for any artifact type
- Do not combine artifact types prematurely — start with clear separation

---

## Setup Steps

After pasting this kickoff document, ask the AI to:

1. Create the repository directory structure per governance model §3
2. Create the CLAUDE.md project instruction file
3. Start with the playbook — define the proposed artifact flow
4. Validate the artifact list before building anything
